{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928cfc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 18:22:37.369463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746804157.392635   67996 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746804157.399535   67996 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746804157.417617   67996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804157.417636   67996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804157.417639   67996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746804157.417641   67996 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-09 18:22:37.424326: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS_TOKEN=<|im_start|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd37e20c1b74cdbb0173f465f96a1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 110/110 [21:19<00:00, 11.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Test Results\n",
      "========================================\n",
      "Total Accuracy: 41.65%\n",
      "\n",
      "Accuracy by Subject:\n",
      "subject_en\n",
      "marketing                             69.23%\n",
      "us_foreign_policy                     68.00%\n",
      "international_law                     67.77%\n",
      "logical_fallacies                     60.74%\n",
      "sociology                             60.20%\n",
      "management                            60.19%\n",
      "jurisprudence                         58.33%\n",
      "computer_security                     57.00%\n",
      "medical_genetics                      57.00%\n",
      "high_school_psychology                56.15%\n",
      "business_ethics                       56.00%\n",
      "miscellaneous                         52.49%\n",
      "clinical_knowledge                    52.45%\n",
      "astronomy                             51.32%\n",
      "human_aging                           51.12%\n",
      "electrical_engineering                51.03%\n",
      "philosophy                            50.80%\n",
      "high_school_computer_science          50.00%\n",
      "college_computer_science              50.00%\n",
      "public_relations                      48.18%\n",
      "nutrition                             48.04%\n",
      "high_school_microeconomics            47.90%\n",
      "high_school_biology                   47.10%\n",
      "high_school_macroeconomics            46.92%\n",
      "college_medicine                      46.82%\n",
      "human_sexuality                       46.56%\n",
      "moral_disputes                        46.53%\n",
      "high_school_geography                 46.46%\n",
      "world_religions                       46.20%\n",
      "prehistory                            45.06%\n",
      "college_mathematics                   45.00%\n",
      "formal_logic                          44.44%\n",
      "anatomy                               44.44%\n",
      "elementary_mathematics                43.65%\n",
      "high_school_chemistry                 42.86%\n",
      "high_school_mathematics               41.85%\n",
      "high_school_government_and_politics   41.45%\n",
      "conceptual_physics                    40.85%\n",
      "professional_psychology               39.38%\n",
      "high_school_statistics                39.35%\n",
      "college_physics                       39.22%\n",
      "virology                              37.95%\n",
      "security_studies                      37.55%\n",
      "college_biology                       36.81%\n",
      "college_chemistry                     36.00%\n",
      "machine_learning                      33.93%\n",
      "abstract_algebra                      33.00%\n",
      "professional_accounting               31.91%\n",
      "professional_medicine                 29.78%\n",
      "high_school_physics                   28.48%\n",
      "high_school_european_history          27.88%\n",
      "econometrics                          26.32%\n",
      "global_facts                          26.00%\n",
      "moral_scenarios                       24.58%\n",
      "professional_law                      23.86%\n",
      "high_school_world_history             22.78%\n",
      "high_school_us_history                19.12%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "\n",
    "MODEL_NAME = \"qwen-1.5b-webglm\"\n",
    "MODEL_PATH = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "SYSTEM = [{\"role\": \"system\", \"content\": \"Ты — экспертная система Compressa RAG. Предоставляющая точные и релевантные ответы на вопросы.\"}]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
    "\n",
    "BOS_TOKEN = tokenizer.bos_token if tokenizer.bos_token else tokenizer.additional_special_tokens[0] \n",
    "print(f\"BOS_TOKEN={BOS_TOKEN}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"../../qwen1_5b-v100-bs_12_2-1epoch-webglm_ft/merged_model\",  # Путь к объединенной модели\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# subjects = [\"high_school_biology\"]\n",
    "\n",
    "subjects = [\"abstract_algebra\", \"anatomy\", \"astronomy\", \"business_ethics\", \"clinical_knowledge\",\n",
    "             \"college_biology\", \"college_chemistry\", \"college_computer_science\", \"college_mathematics\",\n",
    "               \"college_medicine\", \"college_physics\", \"computer_security\", \"conceptual_physics\", \"econometrics\",\n",
    "                 \"electrical_engineering\", \"elementary_mathematics\", \"formal_logic\", \"global_facts\",\n",
    "                   \"high_school_biology\", \"high_school_chemistry\", \"high_school_computer_science\",\n",
    "                     \"high_school_european_history\", \"high_school_geography\", \"high_school_government_and_politics\",\n",
    "                       \"high_school_macroeconomics\", \"high_school_mathematics\", \"high_school_microeconomics\",\n",
    "                         \"high_school_physics\", \"high_school_psychology\", \"high_school_statistics\", \"high_school_us_history\",\n",
    "                           \"high_school_world_history\", \"human_aging\", \"human_sexuality\", \"international_law\",\n",
    "                             \"jurisprudence\", \"logical_fallacies\", \"machine_learning\", \"management\", \"marketing\",\n",
    "                               \"medical_genetics\", \"miscellaneous\", \"moral_disputes\", \"moral_scenarios\", \"nutrition\",\n",
    "                                 \"philosophy\", \"prehistory\", \"professional_accounting\", \"professional_law\",\n",
    "                                   \"professional_medicine\", \"professional_psychology\", \"public_relations\",\n",
    "                                     \"security_studies\", \"sociology\", \"us_foreign_policy\", \"virology\", \"world_religions\"]\n",
    "\n",
    "\n",
    "all_datasets = {subject: datasets.load_dataset(\"NLPCoreTeam/mmlu_ru\", name=subject, split=\"test\") for subject in subjects}\n",
    "\n",
    "test_dfs = []\n",
    "for subject in subjects:\n",
    "    dataset = all_datasets[subject]\n",
    "    df = dataset.to_pandas()\n",
    "    int2str = dataset.features['answer'].int2str\n",
    "    df['answer'] = df['answer'].map(int2str)\n",
    "    df.insert(0, 'subject_en', subject)\n",
    "    test_dfs.append(df)\n",
    "\n",
    "test_df = pd.concat(test_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def create_prompt(row):\n",
    "    return (\n",
    "        f\"Дан вопрос по теме {row['subject_en']}: {row['question_ru']}. Варианты ответа:\\n\"\n",
    "        f\"A) {row['choices_ru'][0]}\\nB) {row['choices_ru'][1]}\\nC) {row['choices_ru'][2]}\\nD) {row['choices_ru'][3]}\\n\"\n",
    "        \"Твой ответ должен быть в формате 'Ответ: <Буква>'.\\n\"\n",
    "        \"Закончи ответ, указав только одну букву: A, B, C или D.\\n\"\n",
    "    )\n",
    "\n",
    "def generate_conversation(row):\n",
    "    formatted_message = [SYSTEM] + [\n",
    "        {\"role\": \"user\", \"content\": create_prompt(row)},\n",
    "    ]\n",
    "    return formatted_message\n",
    "\n",
    "def extract_answer(text):\n",
    "    text = text.upper().strip()\n",
    "\n",
    "    explicit_pattern = re.search(\n",
    "        r\"(?:Ответ|ANSWER|Правильный ответ|Answer)[\\s:\\-—]*([A-D])\", \n",
    "        text\n",
    "    )\n",
    "    if explicit_pattern:\n",
    "        return explicit_pattern.group(1)\n",
    "\n",
    "    for char in text:\n",
    "        if char in {'A','B','C','D'}:\n",
    "            return char\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def evaluate_test(df, model, tokenizer):\n",
    "    device = model.device\n",
    "    df['prediction'] = ''\n",
    "    \n",
    "    for i in tqdm(range(0, len(df), BATCH_SIZE), desc=\"Processing batches\"):\n",
    "        batch = df.iloc[i:i+BATCH_SIZE]\n",
    "        prompts = [generate_conversation(row) for _, row in batch.iterrows()]\n",
    "        chat_prompts = tokenizer.apply_chat_template(\n",
    "            prompts,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        # chat_prompts = [prompt + f\"{BOS_TOKEN}assistant\\n\" for prompt in chat_prompts]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            chat_prompts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=30,\n",
    "                do_sample=False,\n",
    "                temperature=None,\n",
    "                top_p=None,\n",
    "                top_k=None\n",
    "            )\n",
    "        \n",
    "        decoded = tokenizer.batch_decode(\n",
    "            outputs[:, inputs.input_ids.shape[1]:], \n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        \n",
    "        for j, text in enumerate(decoded):\n",
    "            # print(f\"---------------------------------------------------\\n{text.strip()}\\n---------------------------------------------------\")\n",
    "            answer = extract_answer(text)\n",
    "            df.at[i+j, 'prediction'] = answer\n",
    "\n",
    "    df['correct'] = df['answer'] == df['prediction']\n",
    "    total_acc = df['correct'].mean()\n",
    "    subject_acc = df.groupby('subject_en')['correct'].mean()\n",
    "\n",
    "\n",
    "    return total_acc, subject_acc\n",
    "\n",
    "\n",
    "print(\"Starting evaluation...\")\n",
    "total_accuracy, subject_accuracy = evaluate_test(test_df, model, tokenizer)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*40}\\nTest Results\\n{'='*40}\")\n",
    "print(f\"Total Accuracy: {total_accuracy:.2%}\")\n",
    "print(\"\\nAccuracy by Subject:\")\n",
    "print(subject_accuracy.sort_values(ascending=False).to_string(float_format=\"{:,.2%}\".format))\n",
    "\n",
    "\n",
    "test_df.to_csv(f\"../result/mmlu_{MODEL_NAME}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb589946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
