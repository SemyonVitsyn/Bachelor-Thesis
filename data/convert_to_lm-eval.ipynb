{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c6ccd1-47e0-4471-9217-92944df7eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import random\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "# Загрузка данных из xlsx файла\n",
    "df = pd.read_excel('webglm_full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed6448bd-7dac-4735-b4d3-6ae4fb7ff3e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43579"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11d19b1-97a4-4266-8123-d98dcc81788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sources(text):\n",
    "    # Регулярное выражение для поиска источников вида [число]\n",
    "    pattern = r'\\[\\d+\\]'\n",
    "    sources = re.findall(pattern, text)\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f9bb89-a6d2-4e8a-83ce-583b9ef6168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6557"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def create_llama_dataset(df: pd.DataFrame) -> List[Dict]:\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        if len(find_sources(row['answer'])) > 0:\n",
    "            question = row['question']\n",
    "            answer = str(row['answer'])\n",
    "            examples = ast.literal_eval(row[\"references\"]) if isinstance(row['references'], str) else []\n",
    "            \n",
    "            dataset_item = {\n",
    "                \"question\": question,\n",
    "                \"answer\": answer,\n",
    "                \"references\": examples\n",
    "            }\n",
    "            dataset.append(dataset_item)\n",
    "    return dataset\n",
    "\n",
    "# Применение функции к вашему датасету\n",
    "llama_dataset = create_llama_dataset(df)\n",
    "len(llama_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739a73ab-e029-4562-8b06-24d0e036ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты — экспертная система Compressa RAG, \"\n",
    "    \"предоставляющая точные и релевантные ответы на вопросы, \"\n",
    "    \"используя только предоставленную контекстную информацию. \"\n",
    "    \"Отвечай на русском языке.\"\n",
    ")\n",
    "REJECT_ANSW = \"К сожалению, ответа на вопрос нет в упомянутых источниках\"\n",
    "\n",
    "def get_summary_prompt(context_list, question):\n",
    "    context = ''\n",
    "    for i, c in enumerate(context_list):\n",
    "        context += f'Источник [{i+1}]:'+\"\\n\"+c+\"\\n\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"# Контекстная информация:\\n\\n{context}\\n\\n\"\n",
    "        \"---\\n\"\n",
    "        \"# Инструкции:\\n\\n\"\n",
    "        \"1. Дай полный и краткий ответ на вопрос, используя только информацию из контекста.\\n\"\n",
    "        \"2. Укажи номер источника в квадратных скобках после использовании фактов из него, например: [1].\\n\"\n",
    "        \"3. Каждый ответ должен содержать хотя бы одну ссылку на источник.\\n\"\n",
    "        \"4. Ссылайся на источник только если информация взята из него.\\n\"\n",
    "        f\"5. Если ответа на вопрос нет в источниках, ответь: \\\"{REJECT_ANSW}\\\".\\n\"\n",
    "        \"6. Не используй знания вне предоставленного контекста.\\n\\n\"\n",
    "        \"7. Будь очень внимательна к условиям, которым твой ответ не должен противоречить. \"\n",
    "        \"Пример: товар для доставки не должен попадать в определенную категорию.\\n\\n\"\n",
    "        \"# Пример:\\n\\n\"\n",
    "        \"**Контекстная информация:**\\n\"\n",
    "        \"Источник [1]:\\n\"\n",
    "        \"Всегда носите защитные очки при работе с оборудованием.\\n\\n\"\n",
    "        \"Источник [2]:\\n\"\n",
    "        \"Перед началом работы проверьте оборудование на наличие повреждений.\\n\\n\"\n",
    "        \"**Вопрос:** Нужно ли носить защитные очки при работе с оборудованием?\\n\\n\"\n",
    "        \"**Ответ:** Да, при работе с оборудованием необходимо носить защитные очки [1].\\n\\n\"\n",
    "        \"---\\n\"\n",
    "        f\"# Вопрос:\\n\\n{question}\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def update_refs_number(answer, old_numbers, new_numbers):\n",
    "    for old, new in zip(old_numbers, new_numbers):\n",
    "        answer = answer.replace(f\"[{old}]\", f\"[{new}]\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02bb545c-5818-49fb-baf2-db08d34bdc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_val_json = []\n",
    "for i, q in enumerate(llama_dataset[:3000]):\n",
    "    main_val_json.append({\n",
    "        \"messages\": [\n",
    "            {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "            {\"content\": get_summary_prompt(q[\"references\"], q[\"question\"]), \"role\": \"user\"},\n",
    "            {\"content\": q[\"answer\"], \"role\": \"assistant\"}\n",
    "        ],\n",
    "        \"source\": \"human\",\n",
    "        \"opus_score\": 10,\n",
    "        \"landuage\": \"Russian\"\n",
    "    })\n",
    "\n",
    "with open(\"sft_train.jsonl\", \"w\") as json_file:\n",
    "    for item in main_val_json:\n",
    "        json.dump(item, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7d960e-9d49-4b52-8538-7469be123291",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_json = []\n",
    "slice_dataset = llama_dataset[3000:3500]\n",
    "max_refs = 100\n",
    "\n",
    "if len(slice_dataset) < max_refs:\n",
    "    max_refs = len(slice_dataset)\n",
    "    \n",
    "for i, q in enumerate(slice_dataset):\n",
    "    true_refs = q[\"references\"]\n",
    "    all_refs = []\n",
    "    get_refs_number = i+1\n",
    "    while len(all_refs) < max_refs:       \n",
    "        if get_refs_number > len(slice_dataset)-1:\n",
    "            get_refs_number = 0\n",
    "            \n",
    "        all_refs += slice_dataset[get_refs_number][\"references\"]\n",
    "        get_refs_number += 1\n",
    "\n",
    "    all_refs += true_refs\n",
    "    random.shuffle(all_refs)\n",
    "    new_numbers = [all_refs.index(ref) + 1 for ref in true_refs]\n",
    "    answer = update_refs_number(q[\"answer\"], list(range(1, len(new_numbers)+1)), new_numbers)\n",
    "    main_json.append({\n",
    "        \"messages\": [\n",
    "            {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "            {\"content\": get_summary_prompt(all_refs, q[\"question\"]), \"role\": \"user\"},\n",
    "            {\"content\": answer, \"role\": \"assistant\"}\n",
    "        ],\n",
    "        \"source\": \"human\",\n",
    "        \"opus_score\": 10,\n",
    "        \"landuage\": \"Russian\"\n",
    "    })\n",
    "\n",
    "with open(\"sft_rag_val.jsonl\", \"w\") as json_file:\n",
    "    for item in main_json:\n",
    "        json.dump(item, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "642e351d-d246-4879-9b39-58a0607ade76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23755"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_json[1][\"messages\"][1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "395594c6-9080-40b9-a398-bc7c2473ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:5000/v1\",\n",
    "    api_key=\"token-123\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "380160d3-da3e-4f07-a783-894e2b5f7657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Почему люди, которые сильно пьют, становятся старше.\n",
      "ОТВЕТ НЕЙРОСЕТИ Люди, которые сильно пьют, могут стать старше по нескольким причинам: их кожа может стать старше, чем она должна быть, и они могут набрать вес.Это связано с тем, что алкоголь может улучшить процесс старения в целом, заставляя людей стареть быстрее, чем обычно.Он также может оказать непосредственное влияние на определенные части тела и их психическое здоровье с возрастом.[14] Кроме того, алкоголь может также преждевременно заставлять стареть части тела, которые вы не можете видеть, например, мозг.[46] \n",
      "\n",
      "ОТВЕТ ИЗ ДАТАСЕТА Сильное употребление алкоголя может привести к быстрому физическому старению, включая изменения физического внешнего вида, такие как развитие серого кольца в глазу (аркус роговицы) и изменения кожи. Он также может заставлять мозг стареть, что приводит к снижению производительности в тестах исполнительной функции. Алкоголь также связан с повышенным риском возникновения медицинских проблем с возрастом, таких как остеопороз, диабет, высокое кровяное давление, рак, язвы, расстройство настроения, потеря памяти и некоторые расстройства.\n"
     ]
    }
   ],
   "source": [
    "num = 35\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"RAG\",\n",
    "  messages=main_json[num][\"messages\"][:2]\n",
    ")\n",
    "\n",
    "print(slice_dataset[num][\"question\"])\n",
    "print(\"ОТВЕТ НЕЙРОСЕТИ\", completion.choices[0].message.content, \"\\n\")\n",
    "print(\"ОТВЕТ ИЗ ДАТАСЕТА\", main_json[num][\"messages\"][2][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dddb7ffe-1b34-40e1-a672-6f9bca5b8dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sft_rag_train.jsonl\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        data = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52315981-5a6e-4f53-afc8-64d0ecd81ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Если вы съели слишком много или выпили слишком много жидкости, пища может находиться в вашем желудке слишком долго и вызывать гастропарез или задержку опустошения желудка.[102] Кроме того, если вы употребляли жидкости или продукты, содержащие добавленный сахар или другие подсластители, пили слишком много алкоголя, принимали лекарства, которые вызывают задержку жидкости или имеют слабительный эффект, или из-за другого медицинского состояния, такого как гастрит, жидкость может проникать в ваш желудок из неожиданного источника.[102] Наконец, если вы съели небольшую еду и испытали разжигание, пища может перемещаться через пищеварие.',\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"messages\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12b3d7f7-3eb4-458e-8290-f27bbc1720a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_name):\n",
    "    with open(file_name, encoding=\"utf-8\") as r:\n",
    "        return [json.loads(line) for line in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64b1009-be23-4ea1-98ce-4881ba135209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = read_jsonl(\"sft_rag_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0334fafd-3b06-4e41-ab92-34b377c5ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_records = read_jsonl(\"sft_rag_train.jsonl\")\n",
    "val_records = read_jsonl(\"sft_rag_val.jsonl\")\n",
    "\n",
    "datasets = []\n",
    "for records in (train_records, val_records):\n",
    "    print(records)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3776ccfe-4821-4bb6-9623-38b0d9551ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_records), len(val_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754c97dd-d425-453a-80bc-6c1202f7b913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec = (train_records[1], val_records[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8835537-476a-47d8-9a39-c21909fcf37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[11, 22, 33, 44, 55, 66, 77, 88]\n"
     ]
    }
   ],
   "source": [
    "for i in ([1,2,3,4,5,6,7,8,9], [11,22,33,44,55,66,77,88]):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
