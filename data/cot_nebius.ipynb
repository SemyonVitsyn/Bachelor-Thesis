{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import asyncio\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных из xlsx файла\n",
    "df = pd.read_excel('webglm_full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_llama_dataset(df: pd.DataFrame) -> List[Dict]:\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = str(row['answer'])\n",
    "        examples = ast.literal_eval(row[\"references\"]) if isinstance(row['references'], str) else []\n",
    "        \n",
    "        dataset_item = {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"references\": examples\n",
    "        }\n",
    "        dataset.append(dataset_item)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = create_llama_dataset(df)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"NEBIUS_API_KEY\")\n",
    "\n",
    "client = AsyncOpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "COT_SYSTEM_PROMPT = (\n",
    "    \"Ты умный ассистент, который дополняет ответ последовательностью рассуждений.\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cot_prompt(context_list, question, answer):\n",
    "    context = ''\n",
    "    for i, c in enumerate(context_list):\n",
    "        context += f'Источник [{i+1}]:'+\"\\n\"+c+\"\\n\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"# Контекстная информация:\\n\\n{context}\\n\\n\"\n",
    "        f\"# Вопрос:\\n\\n{question}\\n\"\n",
    "        f\"# Оригинальный ответ:\\n\\n{answer}\\n\"\n",
    "        f\"# Задача:\\n\\n\"\n",
    "        \"Твоя задача состоит в том, чтобы дать более детальный ответ\" \\\n",
    "        \"на поставленный вопрос, используя исключительно информацию из контекста.\\n\" \\\n",
    "        \"Для этого последовательно порассуждай про то, какую информацию хочет узнать пользователь\" \\\n",
    "        \"и как информация из оригинального ответа с этим соотносится.\\n\" \\\n",
    "        \"В своем ответе не ссылайся на оригинальный ответ, но учти, что он абсолютно корректен \" \\\n",
    "        \"и тебе нужно лишь дать более расширенную его версию.\\n\"\n",
    "        \"Указывай номер источника, про который рассуждаешь.\\n\" \n",
    "        \"Последний абзац должен начинаться со слова ОТВЕТ:\\\\n и содержать полный ответ на поставленный вопрос.\\n\"\n",
    "        \"В нем особенно важно указывать номера использованных источников.\" \\\n",
    "        f\"# Твой расширенный ответ:\\n\\n\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_llm(user_prompt : str, model : str, semaphore : asyncio.Semaphore, system_prompt : str = None):\n",
    "    async with semaphore:\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        return await client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages, \n",
    "            temperature=0.6,\n",
    "            max_completion_tokens=1200\n",
    "        )\n",
    "    \n",
    "\n",
    "async def process_task(task_id, user_prompt, model, semaphore, system_prompt=None):\n",
    "    try:\n",
    "        response = await run_llm(\n",
    "            user_prompt=user_prompt,\n",
    "            model=model,\n",
    "            semaphore=semaphore,\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "        return {\n",
    "            \"task_id\": task_id,\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"task_id\": task_id,\n",
    "            \"error\": str(e),\n",
    "            \"status\": \"failed\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing LLM requests: 100%|██████████| 3579/3579 [10:06<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "semaphore = asyncio.Semaphore(600)\n",
    "offset = 40000\n",
    "package_size = 5000\n",
    "\n",
    "tasks = [process_task(\n",
    "    task_id=offset + i,\n",
    "    user_prompt=get_cot_prompt(row[\"references\"], row[\"question\"], row[\"answer\"]),\n",
    "    model=\"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "    semaphore=semaphore,\n",
    "    system_prompt=COT_SYSTEM_PROMPT)\n",
    "    for i, row in enumerate(dataset[offset : min(offset+package_size, len(dataset))])\n",
    "]\n",
    "\n",
    "results = []\n",
    "with tqdm_asyncio(total=len(tasks), desc=\"Processing LLM requests\") as pbar:\n",
    "    for coro in asyncio.as_completed(tasks):\n",
    "        result = await coro\n",
    "        results.append(result)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort(key=lambda x: x['task_id'])\n",
    "\n",
    "for result in results:\n",
    "    if result['status'] == \"failed\":\n",
    "        print(result['task_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm_full_cot.jsonl\", \"a\") as json_file:\n",
    "    for result in results:\n",
    "        data = ({\n",
    "            \"question\": dataset[result['task_id']]['question'],\n",
    "            \"answer\": result['content'],\n",
    "            \"references\": dataset[result['task_id']]['references']\n",
    "        })\n",
    "\n",
    "        json.dump(data, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я читаю очень глупую книгу, но в ней есть часть, относящаяся к статистике...\n",
      "\n",
      "\n",
      "\n",
      "Пользователь упоминает, что он читает книгу, относящуюся к статистике, и хочет узнать больше о ней. Из контекста мы понимаем, что книга, вероятно, не о технической стороне статистики, а скорее о том, как критически мыслить, когда сталкиваешься с данными и статистикой [2]. Это означает, что книга может быть более ориентирована на понимание того, как статистика и ее представление могут быть использованы для обмана или для предоставления ценной информации [1].\n",
      "\n",
      "Книга, вероятно, написана экономистом, который также является обозревателем и вещателем, и, возможно, почетным членом Королевского статистического общества [3]. Она состоит из 10 правил, которые помогают читателю понять, как критически мыслить, когда он видит статистику, и как проверить ее правдивость [3]. Эти правила не требуют технических знаний, таких как формулы или понимание p-значения или среднего против медианы [2], [3].\n",
      "\n",
      "Книга также может содержать интересные примеры и показывать, как статистика может помочь нам увидеть вещи, которые почти невозможно увидеть иначе [4], [5]. Автор книги, Тим Харфорд, делает аргумент, что, хотя мы должны быть осторожны с статистикой, мы не должны быть слишком циничными в отношении нее, потому что она может быть очень полезной [5].\n",
      "\n",
      "ОТВЕТ:\n",
      "Пользователь, вероятно, ищет информацию о книге, которая помогает читателю критически мыслить о статистике и данных, без необходимости технических знаний. Эта книга, вероятно, написана Тимом Харфордом, экономистом и почетным членом Королевского статистического общества, и состоит из 10 правил, которые помогают понять, как проверить правдивость статистики [2], [3]. Книга содержит интересные примеры и показывает, как статистика может быть полезной [4], [5], и автор делает аргумент, что мы должны быть осторожны, но не слишком циничными в отношении статистики [1], [5]. Использованные источники: [1], [2], [3], [4], [5].\n",
      "\n",
      "\n",
      "\n",
      "['\"Слава Тиму Харфорду: \"\"Статистика - жизненно важный инструмент для понимания мира, но мы должны быть информированными, вдумчивыми интерпретаторами того, что нам говорят, мы должны быть осведомлены о том, как статистика и ее представление могут быть отличными.\"\"\"', 'Некоторые из них были немного шокирующими, но при повторном размышлении не очень удивительными. например, было исследование (одно исследование), которое показало, что люди имеют предзнание, опубликованное в журнале личности. это не книга о математике и статистике. не нужны формулы. это очень хорошая книга, которая понравится многим типам читателей. это действительно больше о психологии статистики и о том, какие вопросы задавать, когда вы видите данные, чтобы помочь вам решить, действительно ли данные отражают то, что утверждается.', 'Она состоит из 10 правил, рассказывающих, как критически мыслить, когда вы видите статистику (цифры, исследования, диаграммы). Хорошая новость: ни одна из них не была технической (вы знаете, p-значение или среднее против медианы), все было за пределами технических. Правила были о bei Эта книга была написана экономистом, который также является обозревателем и вещателем, не говоря уже о почетном членом Королевского статистического общества.', '\"В то же время, думая об этом обзоре, я задумался о том, что, читая это, я узнал как об алгоритмах, так и о работе Флоренс Найтингейл. Я сомневаюсь, что это можно сказать о многих книгах! Каждая глава предлагает статистические примеры, а затем рассматривает, как обычный человек может понять информацию.', 'Это мощная история! Аргумент Харфорда заключается в том, что, хотя мы должны быть осторожны, мы не должны быть слишком циничными в отношении статистики, потому что они могут показать нам вещи, которые почти невозможно увидеть иначе.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"webglm_full_cot.jsonl\", \"r\") as file:\n",
    "    row = json.loads(file.readlines()[39999])\n",
    "\n",
    "print(row['question'])\n",
    "print('\\n\\n')\n",
    "print(row['answer'])\n",
    "print('\\n\\n')\n",
    "print(row['references'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43579\n"
     ]
    }
   ],
   "source": [
    "with open(\"webglm_full_cot.jsonl\", \"r\") as file:\n",
    "    print(len(file.readlines()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
