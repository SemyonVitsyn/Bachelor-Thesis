{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7748c7fe",
   "metadata": {},
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6439d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "def synth_dict_simple(num_examples=1100, num_dicts=150, train_split=1000):\n",
    "    dataset = []\n",
    "    for _ in range(num_examples):\n",
    "        # Генерация золотого ключа\n",
    "        golden_key = random.randint(100, 9999)\n",
    "        \n",
    "        # Случайное значение для золотого ключа\n",
    "        golden_value = random.randint(100, 9999)\n",
    "        \n",
    "        # Выбор словаря для золотого ключа\n",
    "        golden_dict_id = random.randint(1, num_dicts)\n",
    "        \n",
    "        # Генерация всех словарей\n",
    "        context = []\n",
    "        for dict_id in range(1, num_dicts + 1):\n",
    "            size = random.randint(2, 4)\n",
    "            \n",
    "            entries = {}\n",
    "            if dict_id == golden_dict_id:\n",
    "                entries[golden_key] = golden_value\n",
    "                size = size - 1\n",
    "                \n",
    "            # Генерация остальных ключей\n",
    "            existing = set()\n",
    "            for _ in range(size):\n",
    "                for _ in range(10):  # Попытки генерации\n",
    "                    key = random.randint(100, 9999)\n",
    "                    \n",
    "                    # Проверка на конфликты\n",
    "                    if key == golden_key or key in existing:\n",
    "                        continue\n",
    "                    \n",
    "                    existing.add(key)\n",
    "                    entries[key] = random.randint(100, 9999)\n",
    "                    break\n",
    "            \n",
    "            # Форматирование словаря\n",
    "            dict_str = f\"Cловарь [{dict_id}] {{\"\n",
    "            dict_str += \", \".join(f\"{k}: {v}\" for k, v in entries.items())\n",
    "            dict_str += \"}\"\n",
    "            context.append(dict_str)\n",
    "        \n",
    "        # Формирование ответа\n",
    "        answer = (\n",
    "            f'{{\\n'\n",
    "            f'  \"значение\": {golden_value},\\n'\n",
    "            f'  \"номер_словаря\": {golden_dict_id}\\n'\n",
    "            f'}}'\n",
    "        )\n",
    "                \n",
    "        dataset.append({\n",
    "            \"key\": golden_key,\n",
    "            \"context\": \"\\n\".join(context),\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    \n",
    "    return dataset[:train_split], dataset[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "182a3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = synth_dict_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3d7ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"значение\": 4765,\n",
      "  \"номер_словаря\": 24\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d393466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\") #meta-llama/Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d128ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6952\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(train_data[0]['context'], add_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4842\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(train_data[0]['context'], add_special_tokens=False))) # llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdb79b",
   "metadata": {},
   "source": [
    "# Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98231427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_dict_hard(num_examples=1600, num_dicts=80, train_split=1500):\n",
    "    dataset = []\n",
    "    for _ in range(num_examples):\n",
    "        # Генерация золотых чисел\n",
    "        num_golden = random.choice([3, 4])\n",
    "        golden_numbers = random.sample(range(100, 1000), num_golden)\n",
    "        \n",
    "        # Случайное значение для золотого ключа\n",
    "        golden_value = random.randint(1000, 9999)\n",
    "        \n",
    "        # Выбор словаря для золотого ключа\n",
    "        golden_dict_id = random.randint(1, num_dicts)\n",
    "        \n",
    "        # Генерация всех словарей\n",
    "        context = []\n",
    "        for dict_id in range(1, num_dicts + 1):\n",
    "            size = random.randint(2, 4)\n",
    "            \n",
    "            entries = {}\n",
    "            if dict_id == golden_dict_id:\n",
    "                # Генерация золотого ключа\n",
    "                shuffled = list(golden_numbers)\n",
    "                random.shuffle(shuffled)\n",
    "                golden_key = tuple(shuffled)\n",
    "                entries[golden_key] = golden_value\n",
    "                size = size - 1\n",
    "                \n",
    "            # Генерация остальных ключей\n",
    "            existing = set()\n",
    "            for _ in range(size):\n",
    "                for _ in range(10):  # Попытки генерации\n",
    "                    length = random.choice([3, 4])\n",
    "                    nums = tuple(random.choices(range(100, 1000), k=length))\n",
    "                    sorted_nums = tuple(sorted(nums))\n",
    "                    \n",
    "                    # Проверка на конфликты\n",
    "                    if length == num_golden and sorted_nums == tuple(sorted(golden_numbers)):\n",
    "                        continue\n",
    "                    if sorted_nums in existing:\n",
    "                        continue\n",
    "                    \n",
    "                    existing.add(sorted_nums)\n",
    "                    entries[nums] = random.randint(1000, 9999)\n",
    "                    break\n",
    "            \n",
    "            # Форматирование словаря\n",
    "            dict_str = f\"Cловарь [{dict_id}] {{\"\n",
    "            dict_str += \", \".join(f\"{k}: {v}\" for k, v in entries.items())\n",
    "            dict_str += \"}\"\n",
    "            context.append(dict_str)\n",
    "        \n",
    "        # Формирование ответа\n",
    "        answer = (\n",
    "            f'{{\\n'\n",
    "            f'  \"ключ\": {golden_key},\\n'\n",
    "            f'  \"значение\": {golden_value},\\n'\n",
    "            f'  \"номер_словаря\": {golden_dict_id}\\n'\n",
    "            f'}}'\n",
    "        )\n",
    "                \n",
    "        dataset.append({\n",
    "            \"key\": golden_numbers,\n",
    "            \"context\": \"\\n\".join(context),\n",
    "            \"answer\": answer\n",
    "        })\n",
    "    \n",
    "    return dataset[:train_split], dataset[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e43bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = synth_dict_hard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95600d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ключ\": (752, 574, 382),\n",
      "  \"значение\": 6444,\n",
      "  \"номер_словаря\": 41\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3d4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d82d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6561\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(train_data[0]['context'], add_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d191d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4326\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer.encode(train_data[0]['context'], add_special_tokens=False))) # llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fda32",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc7ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты — экспертная система Compressa RAG, предоставляющая точные и релевантные ответы на вопросы\"\n",
    ")\n",
    "\n",
    "def get_simple_prompt(key, context):\n",
    "    prompt = (\n",
    "        f'Выполни задание, используя список словарей ниже.\\n\\n{context}\\n\\n'\n",
    "        'Выше приведен список словарей, в которых каждый ключ и значение являются целыми числами.\\n'\n",
    "        f'Скажи значение по ключу {key}, а также номер словаря, в котором он находится.\\n'\n",
    "        'Ответ должен быть написан в формате json с полями \"значение\", \"номер_словаря\".'\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def get_hard_prompt(key, context):\n",
    "    prompt = (\n",
    "        f'Выполни задание, используя список словарей ниже.\\n\\n{context}\\n\\n'\n",
    "        'Выше приведен список словарей, в которых каждый ключ представляет собой кортеж целых чисел, а каждое значение представляет собой целое число.\\n'\n",
    "        f'Скажи ключ, содержащий целые числа {key} (не обязательно по порядку), его значение и словарь, в котором он находится.\\n'\n",
    "        'Ответ должен быть написан в формате json c полями \"ключ\", \"значение\", \"номер словаря\".'\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b36caef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_simple, val_data_simple = synth_dict_simple()\n",
    "\n",
    "with open('train/synth_needle_simple_train.jsonl', 'w') as f:\n",
    "    for item in train_data_simple:\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_simple_prompt(item[\"key\"], item[\"context\"]), \"role\": \"user\"},\n",
    "                {\"content\": item[\"answer\"], \"role\": \"assistant\"}\n",
    "            ],\n",
    "        })\n",
    "        f.write(json.dumps(data) + '\\n')\n",
    "\n",
    "with open('val/synth_needle_simple_val.jsonl', 'w') as f:\n",
    "    for item in val_data_simple:\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_simple_prompt(item[\"key\"], item[\"context\"]), \"role\": \"user\"},\n",
    "                {\"content\": item[\"answer\"], \"role\": \"assistant\"}\n",
    "            ],\n",
    "        })\n",
    "        f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9456e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_hard, val_data_hard = synth_dict_hard()\n",
    "\n",
    "with open('train/synth_needle_hard_train.jsonl', 'w') as f:\n",
    "    for item in train_data_hard:\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_hard_prompt(item[\"key\"], item[\"context\"]), \"role\": \"user\"},\n",
    "                {\"content\": item[\"answer\"], \"role\": \"assistant\"}\n",
    "            ],\n",
    "        })\n",
    "        f.write(json.dumps(data) + '\\n')\n",
    "\n",
    "with open('val/synth_needle_hard_val.jsonl', 'w') as f:\n",
    "    for item in val_data_hard:\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_hard_prompt(item[\"key\"], item[\"context\"]), \"role\": \"user\"},\n",
    "                {\"content\": item[\"answer\"], \"role\": \"assistant\"}\n",
    "            ],\n",
    "        })\n",
    "        f.write(json.dumps(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b5da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple train: 1000\n",
      "simple val: 100\n",
      "hard train: 1500\n",
      "hard val: 100\n"
     ]
    }
   ],
   "source": [
    "with open(\"train/synth_needle_simple_train.jsonl\", \"r\") as input:\n",
    "    print(f\"simple train: {len(input.readlines())}\")\n",
    "    \n",
    "with open(\"val/synth_needle_simple_val.jsonl\", \"r\") as input:\n",
    "    print(f\"simple val: {len(input.readlines())}\")\n",
    "\n",
    "with open(\"train/synth_needle_hard_train.jsonl\", \"r\") as input:\n",
    "    print(f\"hard train: {len(input.readlines())}\")\n",
    "\n",
    "with open(\"val/synth_needle_hard_val.jsonl\", \"r\") as input:\n",
    "    print(f\"hard val: {len(input.readlines())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002102d3",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "477210fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выполни задание, используя список словарей ниже.\n",
      "\n",
      "Cловарь [1] {(616, 496, 991, 901): 9214, (568, 258, 796): 6616, (366, 837, 616): 1064}\n",
      "Cловарь [2] {(419, 178, 831, 715): 8888, (758, 193, 450): 5517}\n",
      "Cловарь [3] {(554, 589, 604): 4464, (480, 193, 902): 5399}\n",
      "Cловарь [4] {(155, 649, 403): 2225, (739, 665, 606): 3125}\n",
      "Cловарь [5] {(545, 716, 414, 486): 1288, (510, 890, 573): 3753}\n",
      "Cловарь [6] {(257, 239, 459, 333): 2855, (667, 228, 354): 2855, (296, 201, 486, 168): 4454, (724, 784, 520, 850): 6850}\n",
      "Cловарь [7] {(548, 253, 361, 174): 4953, (893, 227, 913, 348): 9076, (439, 659, 560, 185): 2946}\n",
      "Cловарь [8] {(837, 447, 875, 553): 5979, (876, 556, 886): 8120}\n",
      "Cловарь [9] {(810, 977, 727, 169): 8841, (284, 930, 819): 9822, (900, 412, 255, 752): 3374, (134, 730, 820, 931): 2574}\n",
      "Cловарь [10] {(186, 201, 933, 480): 1868, (218, 110, 390, 784): 3728}\n",
      "Cловарь [11] {(234, 942, 205): 4438, (443, 659, 483, 155): 7772, (763, 355, 378): 7316}\n",
      "Cловарь [12] {(893, 198, 191, 601): 3975, (255, 852, 945): 3104}\n",
      "Cловарь [13] {(684, 470, 643, 212): 8320, (244, 782, 266): 9522, (237, 974, 883): 6494}\n",
      "Cловарь [14] {(523, 903, 257, 780): 4576, (986, 611, 382, 804): 2567, (548, 742, 742, 962): 2804}\n",
      "Cловарь [15] {(425, 281, 985, 680): 6043, (729, 789, 839, 727): 5599, (683, 719, 452, 654): 7549, (360, 340, 495, 391): 4594}\n",
      "Cловарь [16] {(782, 737, 181): 4239, (111, 499, 436, 275): 9061}\n",
      "Cловарь [17] {(971, 926, 315): 6541, (856, 204, 938, 629): 8793, (621, 308, 495): 3213, (908, 782, 407): 9362}\n",
      "Cловарь [18] {(749, 820, 466): 6857, (244, 214, 377, 987): 1644}\n",
      "Cловарь [19] {(270, 318, 911, 888): 7851, (203, 134, 714, 552): 1837, (300, 283, 814, 156): 8663, (335, 725, 191): 6083}\n",
      "Cловарь [20] {(669, 622, 176): 3831, (382, 987, 923): 6546, (191, 576, 368, 608): 4334, (512, 316, 142, 199): 7428}\n",
      "Cловарь [21] {(730, 829, 274): 6135, (299, 768, 819): 9671, (610, 929, 421): 9149, (869, 347, 793, 541): 3552}\n",
      "Cловарь [22] {(163, 588, 904, 411): 3870, (530, 575, 461): 9107, (284, 648, 112): 7701}\n",
      "Cловарь [23] {(150, 365, 467, 105): 7854, (765, 717, 467, 117): 5719, (971, 130, 989, 758): 4360, (307, 704, 965, 823): 5858}\n",
      "Cловарь [24] {(710, 291, 671, 852): 3752, (468, 468, 602): 9073, (900, 645, 704): 5108, (731, 773, 326, 971): 1112}\n",
      "Cловарь [25] {(779, 651, 562): 4279, (302, 605, 796, 103): 5462, (363, 928, 291, 925): 9661, (373, 227, 733, 495): 1727}\n",
      "Cловарь [26] {(350, 918, 121): 2979, (630, 932, 359): 7002, (175, 148, 907): 4377, (651, 437, 731): 2005}\n",
      "Cловарь [27] {(160, 700, 827, 918): 4190, (467, 120, 518): 3652, (805, 781, 122, 715): 1389}\n",
      "Cловарь [28] {(339, 359, 885): 7376, (618, 231, 625): 2073, (307, 943, 123, 922): 9663}\n",
      "Cловарь [29] {(643, 671, 687, 927): 9212, (840, 466, 444): 6311}\n",
      "Cловарь [30] {(634, 949, 135, 225): 6808, (640, 795, 872): 7670, (953, 944, 509, 750): 4927}\n",
      "Cловарь [31] {(934, 230, 633): 3984, (297, 185, 764): 9194, (192, 378, 672): 3407}\n",
      "Cловарь [32] {(315, 662, 486, 894): 3893, (788, 543, 400, 858): 2174, (613, 524, 583): 2776, (307, 616, 217): 3969}\n",
      "Cловарь [33] {(164, 949, 442, 382): 5125, (205, 670, 841): 5377}\n",
      "Cловарь [34] {(925, 889, 320, 360): 2250, (729, 305, 782, 181): 2728, (345, 920, 296): 1025}\n",
      "Cловарь [35] {(721, 727, 377, 691): 4032, (543, 680, 242, 901): 9876, (273, 785, 341): 3687, (676, 984, 234): 9619}\n",
      "Cловарь [36] {(713, 102, 602): 5915, (786, 588, 605): 7250, (523, 496, 262, 619): 5508}\n",
      "Cловарь [37] {(641, 264, 465): 8529, (264, 236, 509): 6959, (447, 507, 506, 151): 2577, (796, 408, 786, 333): 3316}\n",
      "Cловарь [38] {(679, 918, 687, 835): 9284, (842, 978, 968): 5883, (930, 642, 531, 701): 3096}\n",
      "Cловарь [39] {(238, 511, 591, 210): 7219, (102, 544, 674, 629): 6864}\n",
      "Cловарь [40] {(304, 450, 305): 9466, (469, 620, 157, 727): 5592}\n",
      "Cловарь [41] {(386, 266, 549, 401): 8632, (692, 853, 826): 4608, (440, 946, 835): 8222, (799, 364, 274, 500): 4613}\n",
      "Cловарь [42] {(307, 729, 258): 4732, (440, 321, 955): 3702}\n",
      "Cловарь [43] {(697, 788, 439, 972): 6675, (737, 387, 376, 486): 3225, (332, 882, 786): 7427}\n",
      "Cловарь [44] {(224, 475, 770, 937): 4317, (189, 518, 797): 1743, (533, 437, 880, 586): 3181, (787, 287, 675, 576): 6671}\n",
      "Cловарь [45] {(106, 660, 554): 1642, (424, 652, 449): 1548, (473, 489, 573): 1833}\n",
      "Cловарь [46] {(574, 939, 526): 1528, (252, 641, 102, 700): 8311, (243, 587, 155, 635): 2214}\n",
      "Cловарь [47] {(419, 801, 746, 659): 7682, (714, 742, 893): 8414, (544, 315, 866): 5160, (938, 276, 580): 2455}\n",
      "Cловарь [48] {(983, 676, 884, 215): 9333, (271, 166, 221, 634): 8542, (819, 625, 267): 1951}\n",
      "Cловарь [49] {(475, 145, 358, 819): 6439, (174, 529, 693, 445): 9475}\n",
      "Cловарь [50] {(866, 749, 702, 906): 7992, (150, 661, 439, 219): 7693}\n",
      "Cловарь [51] {(658, 790, 139, 130): 9233, (524, 352, 741): 2680}\n",
      "Cловарь [52] {(751, 980, 972): 3295, (712, 662, 891): 6724, (378, 561, 882, 911): 2657, (682, 553, 788): 9751}\n",
      "Cловарь [53] {(667, 297, 805, 848): 6481, (380, 718, 589, 267): 8592}\n",
      "Cловарь [54] {(585, 472, 549): 8756, (803, 840, 640): 1213, (488, 599, 948): 4612}\n",
      "Cловарь [55] {(500, 797, 907, 462): 8009, (627, 613, 998, 632): 1198}\n",
      "Cловарь [56] {(193, 348, 886): 9458, (241, 650, 775, 968): 6896}\n",
      "Cловарь [57] {(824, 337, 564): 8038, (531, 535, 916): 7439, (645, 184, 289, 949): 9923}\n",
      "Cловарь [58] {(274, 798, 723, 317): 4221, (988, 660, 274, 110): 7741, (549, 594, 759, 484): 6602}\n",
      "Cловарь [59] {(778, 594, 186, 829): 4322, (318, 902, 316, 550): 9589}\n",
      "Cловарь [60] {(250, 764, 643): 8249, (872, 404, 383): 8432, (943, 293, 668, 499): 3226}\n",
      "Cловарь [61] {(477, 245, 500, 173): 3395, (569, 573, 183): 6718}\n",
      "Cловарь [62] {(499, 680, 983, 648): 1986, (818, 760, 726, 633): 4841}\n",
      "Cловарь [63] {(455, 621, 115): 5774, (526, 547, 329): 1119, (402, 258, 900): 4789, (805, 674, 152, 102): 2769}\n",
      "Cловарь [64] {(149, 980, 733): 5310, (304, 306, 699, 679): 2243}\n",
      "Cловарь [65] {(495, 754, 362, 556): 6096, (991, 563, 284): 8208, (790, 411, 116, 782): 7139, (700, 412, 201): 9946}\n",
      "Cловарь [66] {(623, 610, 696, 262): 9192, (296, 272, 203, 719): 1503}\n",
      "Cловарь [67] {(297, 404, 355): 1033, (524, 391, 758, 854): 2522, (299, 543, 449): 1671}\n",
      "Cловарь [68] {(253, 975, 977, 763): 3949, (615, 892, 746, 218): 1326, (856, 192, 147, 498): 3155}\n",
      "Cловарь [69] {(714, 327, 599): 6062, (595, 918, 616): 5192, (403, 501, 553, 293): 3269, (109, 666, 184, 825): 7352}\n",
      "Cловарь [70] {(490, 662, 551, 430): 2767, (792, 464, 472): 1383}\n",
      "Cловарь [71] {(267, 113, 641, 368): 8700, (428, 853, 865): 7333, (951, 656, 690, 973): 3152}\n",
      "Cловарь [72] {(481, 366, 960, 810): 8628, (123, 579, 836, 460): 5438, (298, 206, 604, 607): 7884, (641, 268, 148, 381): 8744}\n",
      "Cловарь [73] {(615, 353, 735): 4963, (129, 384, 586): 8948, (381, 204, 334): 9057, (739, 958, 917): 2298}\n",
      "Cловарь [74] {(223, 603, 685): 5542, (905, 951, 509): 6852, (484, 817, 416): 5266}\n",
      "Cловарь [75] {(181, 741, 533): 2983, (727, 126, 603, 744): 3585, (836, 749, 162, 457): 5903}\n",
      "Cловарь [76] {(185, 758, 112): 5057, (845, 392, 800): 5702}\n",
      "Cловарь [77] {(807, 932, 841): 1777, (564, 544, 603): 3521, (918, 988, 321, 522): 6901}\n",
      "Cловарь [78] {(290, 639, 695): 9313, (851, 987, 421): 9184}\n",
      "Cловарь [79] {(604, 906, 440, 943): 6829, (227, 532, 681): 3224, (773, 865, 572, 511): 3200}\n",
      "Cловарь [80] {(760, 535, 348, 227): 5339, (281, 218, 456, 602): 7640, (344, 805, 347): 6915}\n",
      "\n",
      "Выше приведен список словарей, в которых каждый ключ представляет собой кортеж целых чисел, а каждое значение представляет собой целое число.\n",
      "Скажи ключ, содержащий целые числа [225, 634, 135, 949] (не обязательно по порядку), его значение и словарь, в котором он находится.\n",
      "Ответ должен быть написан в формате json c полями \"ключ\", \"значение\", \"номер словаря\".\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "with open(\"val/synth_needle_hard_val.jsonl\", \"r\") as input:\n",
    "    item = json.loads(input.readlines()[2])\n",
    "\n",
    "print(item[\"messages\"][1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889a2919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS_TOKEN=<|im_start|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06252b98145b4227a71b0edcab92a282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\", padding_side='left')\n",
    "\n",
    "BOS_TOKEN = tokenizer.bos_token if tokenizer.bos_token else tokenizer.additional_special_tokens[0] \n",
    "print(f\"BOS_TOKEN={BOS_TOKEN}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\",  # Путь к объединенной модели\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "\n",
    "messages = item[\"messages\"]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb75cdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот ответ в требуемом формате JSON:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"ключ\": (634, 949, 135, 225),\n",
      "  \"значение\": 6808,\n",
      "  \"номер_словаря\": 30\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27202d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ключ\": (634, 949, 135, 225),\n",
      "  \"значение\": 6808,\n",
      "  \"номер_словаря\": 30\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(item[\"messages\"][2][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
