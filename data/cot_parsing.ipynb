{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1437291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import asyncio\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc8fdb8",
   "metadata": {},
   "source": [
    "# COT PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64b6e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm_full_cot.jsonl\", \"r\") as input, \\\n",
    "     open(\"webglm_full_cot_parsed.jsonl\", \"w\") as output:\n",
    "    \n",
    "    for idx, line in enumerate(input):\n",
    "    \n",
    "        data = json.loads(line)\n",
    "        cot_answer = data['answer']\n",
    "        \n",
    "        parts = cot_answer.split('ОТВЕТ:', 1)\n",
    "\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        \n",
    "        cot = parts[0].strip() if len(parts) > 0 else ''\n",
    "        answer = parts[1].strip() if len(parts) > 1 else ''\n",
    "        \n",
    "        data['cot'] = cot\n",
    "        data['answer'] = answer\n",
    "        \n",
    "        json_line = json.dumps(data)\n",
    "        output.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71df98e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43487\n"
     ]
    }
   ],
   "source": [
    "# Убрали 100 строк с мусорной разметкой\n",
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as input:\n",
    "    print(len(input.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f242d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что происходит с батареями, когда они перестают работать?\n",
      "\n",
      "\n",
      "\n",
      "Когда пользователь задает вопрос о том, что происходит с батареями, когда они перестают работать, он, вероятно, ищет информацию о процессе, который приводит к потере заряда и возможности повторного использования или переработки батарей. В источнике [1] упоминается, что все батареи в конечном итоге теряют заряд, но не предоставляется конкретного объяснения этого процесса. Однако в источнике [5] более подробно описывается причина, по которой литий-ионные батареи теряют заряд с течением времени, что связано с нежелательной химической реакцией, начинающейся с электродов, содержащих никель.\n",
      "\n",
      "Эта химическая реакция, по-видимому, является ключевым фактором в потере заряда батарей. Кроме того, источник [2] затрагивает тему того, что происходит с аккумуляторами электромобилей, когда они достигают конца своего срока службы, что подразумевает, что существует процесс, связанный с их конечным состоянием. Более конкретно, источник [3] упоминает, что когда батареи достигают конца своего срока службы в электрическом транспортном средстве, основное внимание уделяется их переработке. Это говорит о том, что после того, как батареи перестают работать, они могут быть переработаны.\n",
      "\n",
      "\n",
      "\n",
      "Когда батареи перестают работать, они теряют заряд из-за нежелательной химической реакции, как описано в источнике [5]. Эта реакция происходит между электродами, содержащими никель, и ионами, проходящими через них, что в конечном итоге приводит к потере эффективности и емкости батареи. После того, как батареи достигают конца своего срока службы, особенно в контексте электромобилей (источник [2]), они могут подвергаться переработке, как упоминается в источнике [3]. Таким образом, понимание процесса, связанного с потерей заряда и возможными путями повторного использования или переработки, имеет важное значение, и эта информация может быть найдена в источниках [1], [2], [3] и [5].\n",
      "\n",
      "\n",
      "\n",
      "['В конце концов, все батареи теряют заряд, даже этот монстр. Но почему это происходит? Что объясняет медленное вымирание батарей и есть ли способы продлить их срок службы? Правильно обслуживая батарею, ваши устройства могут в конечном итоге длиться дольше, избавляя вас от необходимости покупать что-то новое.', 'Теперь, когда мы знаем, как работают аккумуляторы электромобилей, что с ними происходит, когда они достигают конца своего срока службы или когда они больше не питают автомобили надежно и быстро?', 'Когда батареи достигают конца своего срока службы в электрическом транспортном средстве, основное внимание уделяется их переработке (как описано выше).', 'Вы знаете, почему батареи теряют заряд, и теперь вы хотите максимизировать их срок службы? Не все ли? К счастью, есть несколько советов и трюков, которыми вы можете следовать, чтобы сохранить свою батарею в лучшем возможном состоянии в течение многих лет.', 'Но, согласно исследованиям Министерства энергетики США, причина, по которой литий-ионные батареи теряют заряд с течением времени, заключается в нежелательной химической реакции, которая начинается с электродов, которые часто включают никель в свой композитный состав.И поскольку мы не можем создать полностью гладкие поверхности внутри батареи, есть все эти маленькие уголки, трещины и трещины, где может возникнуть накопление.Так, когда эти ионы проходят через положительные и отрицательные электроды батареи, некоторые из них начинают застрягать из-за реакции, которую они вызывают, когда они вступают в контакт с никелевым веществом.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as file:\n",
    "    row = json.loads(file.readlines()[5071])\n",
    "\n",
    "print(row['question'])\n",
    "print('\\n\\n')\n",
    "print(row['cot'])\n",
    "print('\\n\\n')\n",
    "print(row['answer'])\n",
    "print('\\n\\n')\n",
    "print(row['references'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e937308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 25.323292018304322\n",
      "cot 492.39370386552304\n",
      "answer 237.87941223814013\n",
      "context 517.8336514360614\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")\n",
    "\n",
    "question_tokens = 0\n",
    "cot_tokens = 0\n",
    "answer_tokens = 0\n",
    "context_tokens = 0\n",
    "\n",
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as file:\n",
    "    samples = len(file.readlines())\n",
    "\n",
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as file:\n",
    "    for idx, line in enumerate(file):\n",
    "        data = json.loads(line)\n",
    "\n",
    "        question_tokens += len(tokenizer.encode(data['question'], add_special_tokens=False))\n",
    "        cot_tokens += len(tokenizer.encode(data['cot'], add_special_tokens=False))\n",
    "        answer_tokens += len(tokenizer.encode(data['answer'], add_special_tokens=False))\n",
    "\n",
    "        context = ''\n",
    "        for i, c in enumerate(data['references']):\n",
    "            context += f'Источник [{i+1}]:'+\"\\n\"+c+\"\\n\\n\"\n",
    "        context_tokens += len(tokenizer.encode(context, add_special_tokens=False))\n",
    "\n",
    "\n",
    "print(f\"question {question_tokens / samples}\")\n",
    "print(f\"cot {cot_tokens / samples}\")\n",
    "print(f\"answer {answer_tokens / samples}\")\n",
    "print(f\"context {context_tokens / samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18523e",
   "metadata": {},
   "source": [
    "# DEFAULT WEBGLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887e871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты — экспертная система Compressa RAG, \"\n",
    "    \"предоставляющая точные и релевантные ответы на вопросы, \"\n",
    "    \"используя только предоставленную контекстную информацию. \"\n",
    "    \"Отвечай на русском языке.\"\n",
    ")\n",
    "REJECT_ANSW = \"К сожалению, ответа на вопрос нет в упомянутых источниках\"\n",
    "\n",
    "def get_summary_prompt(context_list, question):\n",
    "    context = ''\n",
    "    for i, c in enumerate(context_list):\n",
    "        context += f'Источник [{i+1}]:'+\"\\n\"+c+\"\\n\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"# Контекстная информация:\\n\\n{context}\\n\\n\"\n",
    "        \"---\\n\"\n",
    "        \"# Инструкции:\\n\\n\"\n",
    "        \"1. Дай полный и краткий ответ на вопрос, используя только информацию из контекста.\\n\"\n",
    "        \"2. Укажи номер источника в квадратных скобках после использовании фактов из него, например: [1].\\n\"\n",
    "        \"3. Ответ должен содержать хотя бы одну ссылку на источник.\\n\"\n",
    "        \"4. Ссылайся на источник только если информация взята из него.\\n\"\n",
    "        f\"5. Если ответа на вопрос нет в источниках, ответь: \\\"{REJECT_ANSW}\\\".\\n\"\n",
    "        \"6. Не используй знания вне предоставленного контекста.\\n\\n\"\n",
    "        f\"# Вопрос:\\n\\n{question}\\n\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def get_raft_summary_prompt(context_list, question):\n",
    "    context = ''\n",
    "    for i, c in enumerate(context_list):\n",
    "        context += f'Источник [{i+1}]:'+\"\\n\"+c+\"\\n\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"# Контекстная информация:\\n\\n{context}\\n\\n\"\n",
    "        \"---\\n\"\n",
    "        \"# Инструкции:\\n\\n\"\n",
    "        \"1. Сперва порассуждай про то, какую информацию хочет узнать пользователь\" \n",
    "        \"и как информация из контекста с этим соотносится.\\n\"\n",
    "        \"2. В последнем абзаце дай полный и краткий ответ на вопрос, используя только информацию из контекста.\\n\"\n",
    "        \"3. Укажи номер источника в квадратных скобках после использовании фактов из него, например: [1].\\n\"\n",
    "        \"4. Ответ должен содержать хотя бы одну ссылку на источник.\\n\"\n",
    "        \"5. Ссылайся на источник только если информация взята из него.\\n\"\n",
    "        f\"6. Если ответа на вопрос нет в источниках, ответь: \\\"{REJECT_ANSW}\\\".\\n\"\n",
    "        \"7. Не используй знания вне предоставленного контекста.\\n\\n\"\n",
    "        f\"# Вопрос:\\n\\n{question}\\n\\n\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "def update_refs_number(answer, old_numbers, new_numbers):\n",
    "    for old, new in zip(old_numbers, new_numbers):\n",
    "        answer = answer.replace(f\"[{old}]\", f\"[{new}]\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07df1a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43579"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('webglm_full.xlsx')\n",
    "\n",
    "def create_llama_dataset(df: pd.DataFrame) -> List[Dict]:\n",
    "    dataset = []\n",
    "    for _, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = str(row['answer'])\n",
    "        examples = ast.literal_eval(row[\"references\"]) if isinstance(row['references'], str) else []\n",
    "        \n",
    "        dataset_item = {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"references\": examples\n",
    "        }\n",
    "        dataset.append(dataset_item)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = create_llama_dataset(df)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm.jsonl\", \"w\") as file:\n",
    "    for row in dataset:\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_summary_prompt(row[\"references\"], row[\"question\"]), \"role\": \"user\"},\n",
    "                {\"content\": row[\"answer\"], \"role\": \"assistant\"}\n",
    "            ],\n",
    "            \"opus_score\": 10,\n",
    "        })\n",
    "        \n",
    "        json.dump(data, file)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2e9ad",
   "metadata": {},
   "source": [
    "# RAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea9182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42a1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import deque\n",
    "\n",
    "max_refs = 4\n",
    "storage = deque(maxlen=max_refs)\n",
    "\n",
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        storage.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15ae53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as input, \\\n",
    "     open(\"webglm_raft.jsonl\", \"w\") as output:  \n",
    "    for i, row in enumerate(input):\n",
    "        line = json.loads(row)\n",
    "        true_refs = line[\"references\"]\n",
    "        all_refs = []\n",
    "        all_refs += true_refs\n",
    "\n",
    "        for data in storage:\n",
    "            all_refs += data[\"references\"]\n",
    "\n",
    "        random.shuffle(all_refs)\n",
    "        new_numbers = [all_refs.index(ref) + 1 for ref in true_refs]\n",
    "        answer = update_refs_number(line[\"answer\"], list(range(1, len(new_numbers)+1)), new_numbers)\n",
    "        cot = update_refs_number(line[\"cot\"], list(range(1, len(new_numbers)+1)), new_numbers)\n",
    "\n",
    "        storage.append(line)\n",
    "        \n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_raft_summary_prompt(all_refs, line[\"question\"]), \"role\": \"user\"},\n",
    "                {\"content\": cot + \"\\n\\n\" + answer, \"role\": \"assistant\"}\n",
    "            ],\n",
    "            \"opus_score\": 10,\n",
    "        })\n",
    "\n",
    "        if len(tokenizer.encode(tokenizer.apply_chat_template(data[\"messages\"], tokenize=False), add_special_tokens=False)) > 5000:\n",
    "            continue\n",
    "\n",
    "        json.dump(data, output)\n",
    "        output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b770d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_refs = 4\n",
    "storage = deque(maxlen=max_refs)\n",
    "\n",
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        storage.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2850029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm_full_cot_parsed.jsonl\", \"r\") as input, \\\n",
    "     open(\"webglm_raft.jsonl\", \"a\") as output:\n",
    "    for idx, line in enumerate(input):\n",
    "        if idx == 5000:\n",
    "            break\n",
    "\n",
    "        question = json.loads(line)[\"question\"]\n",
    "        \n",
    "        all_refs = []\n",
    "\n",
    "        for data in storage:\n",
    "            all_refs += data[\"references\"]\n",
    "\n",
    "        random.shuffle(all_refs)\n",
    "\n",
    "        data = ({\n",
    "            \"messages\": [\n",
    "                {\"content\": SYSTEM_PROMPT, \"role\": \"system\"},\n",
    "                {\"content\": get_raft_summary_prompt(all_refs, question), \"role\": \"user\"},\n",
    "                {\"content\": REJECT_ANSW, \"role\": \"assistant\"}\n",
    "            ],\n",
    "            \"opus_score\": 10,\n",
    "        })\n",
    "\n",
    "        storage.append(json.loads(line))\n",
    "\n",
    "        if len(tokenizer.encode(tokenizer.apply_chat_template(data[\"messages\"], tokenize=False), add_special_tokens=False)) > 5000:\n",
    "            continue\n",
    "\n",
    "\n",
    "        json.dump(data, output)\n",
    "        output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7388949f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48468\n"
     ]
    }
   ],
   "source": [
    "with open(\"webglm_raft.jsonl\", \"r\") as input:\n",
    "    print(len(input.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe1989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webglm_raft.jsonl\", 'r') as input, \\\n",
    "     open(\"webglm_raft_shuffled.jsonl\", 'w') as output:\n",
    "    lines = input.readlines()\n",
    "    \n",
    "    random.shuffle(lines)\n",
    "\n",
    "    output.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88975f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48468\n"
     ]
    }
   ],
   "source": [
    "with open(\"webglm_raft_shuffled.jsonl\", \"r\") as input:\n",
    "    print(len(input.readlines()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
