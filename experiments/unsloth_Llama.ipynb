{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa8f3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-08 12:13:37.017258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746695617.114885    3072 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746695617.143547    3072 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746695617.341352    3072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746695617.341377    3072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746695617.341380    3072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746695617.341382    3072 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-08 12:13:37.365065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b80fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Tesla V100-SXM2-32GB. Num GPUs = 1. Max memory: 31.733 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # unsloth/Llama-3.2-1B-Instruct\n",
    "max_seq_length = 2048\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_8bit=False,\n",
    "    load_in_4bit=False,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    \n",
    "    # use_flash_attention_2=True,  # –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–ª–∞–≥\n",
    "    # fused_mlp=True,              # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è MLP\n",
    "    # fused_dense=True,            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è dense —Å–ª–æ–µ–≤\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092085d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    "    use_rslora=False,\n",
    "    # use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    "    loftq_config=None,\n",
    ")\n",
    "\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf6061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "def read_jsonl(file_name):\n",
    "    with open(file_name, encoding=\"utf-8\") as r:\n",
    "        return [json.loads(line) for line in r]\n",
    "    \n",
    "data = read_jsonl(\"../Semyon/data/train/sft_d1_train.jsonl\")\n",
    "val_data = read_jsonl(\"../Semyon/data/val/sft_d1_val.jsonl\")\n",
    "dataset = Dataset.from_list(data)\n",
    "val_dataset = Dataset.from_list(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a20c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbcd00e2c19447f8cf5c3ca9339df59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05119219dca1483c9303e74730fa1b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_system_message = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ Compressa RAG. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è —Ç–æ—á–Ω—ã–µ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\"\n",
    "}\n",
    "\n",
    "def generate_conversation(examples):\n",
    "    conversations = []\n",
    "    for messages in examples[\"messages\"]:\n",
    "        formatted_messages = [custom_system_message] + [  # <- –∫–∞—Å—Ç–æ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç\n",
    "            {\"role\": msg[\"role\"], \"content\": msg[\"content\"]}\n",
    "            for msg in messages\n",
    "        ]\n",
    "        conversations.append(formatted_messages)\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "train = tokenizer.apply_chat_template(\n",
    "    dataset.map(generate_conversation, batched=True)[\"conversations\"],\n",
    "    tokenize=False,\n",
    ")\n",
    "\n",
    "val = tokenizer.apply_chat_template(\n",
    "    val_dataset.map(generate_conversation, batched=True)[\"conversations\"],\n",
    "    tokenize=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d43fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 May 2025\n",
      "\n",
      "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ Compressa RAG. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è —Ç–æ—á–Ω—ã–µ –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Read the following text about wearable fitness technology and answer the subsequent questions:      \"Wearable fitness technology includes devices such as fitness trackers, smartwatches, and heart rate monitors. These devices track various health metrics like steps taken, calories burned, and heart rate. Fitness trackers are usually worn on the wrist and provide users with real-time data on their physical activities. Smartwatches not only track fitness metrics but also offer additional functionalities like GPS navigation, notifications from your phone, and sometimes even the capability to make phone calls. Heart rate monitors, often used by athletes, provide accurate readings of the user's heart rate during different types of exercises.\"   a. Categorize the following devices: Fitbit, Apple Watch, Polar Hb. Identify the unique functionalities provided by smartwatches compared to other wearable fitness technologies.   c. Discuss a potential health application for each type of wearable fitness technology mentioned in the text.\n",
      "Answer on russian<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "### –û–±—Å—É–∂–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –æ –Ω–æ—Å–∏–º—ã—Ö —Ñ–∏—Ç–Ω–µ—Å-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö\n",
      "\n",
      "–ü—Ä–µ–∂–¥–µ –≤—Å–µ–≥–æ, –¥–∞–≤–∞–π—Ç–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∫–∞–∂–¥–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏–º –∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:\n",
      "\n",
      "a. –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤:\n",
      "- **Fitbit** - —ç—Ç–æ –±—Ä–µ–Ω–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Ñ–∏—Ç–Ω–µ—Å-—Ç—Ä–µ–∫–µ—Ä—ã, –ø–æ—ç—Ç–æ–º—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ Fitbit –º–æ–∂–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ñ–∏—Ç–Ω–µ—Å-—Ç—Ä–µ–∫–µ—Ä—ã.\n",
      "- **Apple Watch** - —ç—Ç–æ —É–º–Ω—ã–µ —á–∞—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ, –ø–æ–º–∏–º–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ñ–∏—Ç–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫, –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏, —Ç–∞–∫–∏–µ –∫–∞–∫ GPS-–Ω–∞–≤–∏–≥–∞—Ü–∏—è, —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ–≤–µ—Ä—à–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∏.\n",
      "- **Polar Hb** - —ç—Ç–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, —Å–µ—Ä–¥–µ—á–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä (—Ö–æ—Ç—è —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ), –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã —Å–µ—Ä–¥–µ—á–Ω—ã—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–∏–¥–æ–≤ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π.\n",
      "\n",
      "b. –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —É–º–Ω—ã—Ö —á–∞—Å–æ–≤ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –¥—Ä—É–≥–∏–º–∏ –Ω–æ—Å–∏–º—ã–º–∏ —Ñ–∏—Ç–Ω–µ—Å-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏:\n",
      "- GPS-–Ω–∞–≤–∏–≥–∞—Ü–∏—è: –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –º–∞—Ä—à—Ä—É—Ç—ã –≤–æ –≤—Ä–µ–º—è –±–µ–≥–∞ –∏–ª–∏ –≤–µ–ª–æ—Å–∏–ø–µ–¥–Ω—ã—Ö –ø—Ä–æ–≥—É–ª–æ–∫.\n",
      "- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞: –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø—Ä—è–º–æ –Ω–∞ —á–∞—Å—ã, –Ω–µ –¥–æ—Å—Ç–∞–≤–∞—è —Å–º–∞—Ä—Ç—Ñ–æ–Ω.\n",
      "- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–æ–≤–µ—Ä—à–∞—Ç—å —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ã–µ –∑–≤–æ–Ω–∫–∏: —É–º–Ω—ã–µ —á–∞—Å—ã –º–æ–≥—É—Ç —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–ª–µ—Ñ–æ–Ω, –ø–æ–∑–≤–æ–ª—è—è –∑–≤–æ–Ω–∏—Ç—å –∏–ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –∑–≤–æ–Ω–∫–∏.\n",
      "\n",
      "c. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –¥–ª—è –∑–¥–æ—Ä–æ–≤—å—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ –Ω–æ—Å–∏–º–æ–π —Ñ–∏—Ç–Ω–µ—Å-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:\n",
      "- **–§–∏—Ç–Ω–µ—Å-—Ç—Ä–µ–∫–µ—Ä—ã**: –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏, —á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Å–≤–æ—é —Ñ–∏–∑–∏—á–µ—Å–∫—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —Å–ª–µ–¥–∏—Ç—å –∑–∞ —Å–∂–∏–≥–∞–Ω–∏–µ–º –∫–∞–ª–æ—Ä–∏–π.\n",
      "- **–£–º–Ω—ã–µ —á–∞—Å—ã**: –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–≥–æ —Å–ø–µ–∫—Ç—Ä–∞ –∑–¥–æ—Ä–æ–≤—å—è –∏ —Ñ–∏—Ç–Ω–µ—Å-—Ü–µ–ª–µ–π, –≤–∫–ª—é—á–∞—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Å–Ω–∞, –Ω–∞–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –¥–≤–∏–∂–µ–Ω–∏–∏ –∏ –¥–∞–∂–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Ä–æ–≤–Ω—è –∫–∏—Å–ª–æ—Ä–æ–¥–∞ –≤ –∫—Ä–æ–≤–∏ –∏–ª–∏ –≠–ö–ì –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—è—Ö.\n",
      "- **–°–µ—Ä–¥–µ—á–Ω—ã–µ –º–æ–Ω–∏—Ç–æ—Ä—ã**: –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è —Å–ø–æ—Ä—Ç—Å–º–µ–Ω–æ–≤ –∏ –ª—é–¥–µ–π, –∑–∞–Ω–∏–º–∞—é—â–∏—Ö—Å—è –∫–∞—Ä–¥–∏–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞–º–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ –º–æ–≥—É—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å —á–∞—Å—Ç–æ—Ç—É —Å–µ—Ä–¥–µ—á–Ω—ã—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø–æ–º–æ–≥–∞—Ç—å –∏–∑–±–µ–≥–∞—Ç—å –ø–µ—Ä–µ–≥—Ä—É–∑–æ–∫.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92e2254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_tmp = pd.Series(train)\n",
    "val_tmp = pd.Series(val)\n",
    "\n",
    "train_tmp.name = \"text\"\n",
    "val_tmp.name = \"text\"\n",
    "\n",
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_tmp))\n",
    "train_dataset = train_dataset.shuffle(seed = 3407)\n",
    "val_dataset = Dataset.from_pandas(pd.DataFrame(val_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c55d271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34/1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdc86d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffbe57add08417e948f00f922de1dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=20):   0%|          | 0/34640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6f2159d4f54be6967498a71bc62875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=20):   0%|          | 0/1011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    packing = False,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 12,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 50,\n",
    "        num_train_epochs = 1,\n",
    "        learning_rate = 2e-5,\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",  # adamw_8bit\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to=\"wandb\",\n",
    "        output_dir=\"llama-v100-bs_12_2\",\n",
    "        eval_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        dataloader_num_workers=8\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d023483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 34,640 | Num Epochs = 1 | Total steps = 1,443\n",
      "O^O/ \\_/ \\    Batch size per device = 12 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (12 x 2 x 1) = 24\n",
      " \"-____-\"     Trainable parameters = 11,272,192/1,247,086,592 (0.90% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseba-vicin\u001b[0m (\u001b[33mseba-vicin-oxford\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/Alex/wandb/run-20250508_121826-j0xfqhb8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seba-vicin-oxford/huggingface/runs/j0xfqhb8' target=\"_blank\">llama-v100-bs_12_2</a></strong> to <a href='https://wandb.ai/seba-vicin-oxford/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seba-vicin-oxford/huggingface' target=\"_blank\">https://wandb.ai/seba-vicin-oxford/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seba-vicin-oxford/huggingface/runs/j0xfqhb8' target=\"_blank\">https://wandb.ai/seba-vicin-oxford/huggingface/runs/j0xfqhb8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1443' max='1443' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1443/1443 3:39:40, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.937800</td>\n",
       "      <td>1.902725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.676300</td>\n",
       "      <td>1.631617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>1.586840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.597300</td>\n",
       "      <td>1.563779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.594500</td>\n",
       "      <td>1.546911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.510200</td>\n",
       "      <td>1.533495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.537900</td>\n",
       "      <td>1.522028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.582100</td>\n",
       "      <td>1.512389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.558700</td>\n",
       "      <td>1.503936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.512200</td>\n",
       "      <td>1.496387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.529500</td>\n",
       "      <td>1.489628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.468800</td>\n",
       "      <td>1.483085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.531000</td>\n",
       "      <td>1.475158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.444200</td>\n",
       "      <td>1.461545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.476400</td>\n",
       "      <td>1.454852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.441000</td>\n",
       "      <td>1.447483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.450300</td>\n",
       "      <td>1.442070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.481600</td>\n",
       "      <td>1.438760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.441900</td>\n",
       "      <td>1.436202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.430400</td>\n",
       "      <td>1.434476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.465800</td>\n",
       "      <td>1.432609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.447700</td>\n",
       "      <td>1.431342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.440500</td>\n",
       "      <td>1.430231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.424300</td>\n",
       "      <td>1.429273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.440400</td>\n",
       "      <td>1.428450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.390800</td>\n",
       "      <td>1.427810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.421200</td>\n",
       "      <td>1.427426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.471200</td>\n",
       "      <td>1.427179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77e15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"llama-v100-bs_12_2/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d4f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"llama-v100-bs_12_2/pretrain_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a64fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe414d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
